{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define a Data Generator for Efficient Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npz_image_generator(folder, batch_size=32, img_size=(128, 128)):\n",
    "    files = [f for f in os.listdir(folder) if f.endswith('.npz')]\n",
    "    num_files = len(files)\n",
    "    \n",
    "    while True:\n",
    "        for i in range(0, num_files, batch_size):\n",
    "            batch_files = files[i:i + batch_size]\n",
    "            batch_images = []\n",
    "            batch_blurry_images = []\n",
    "            \n",
    "            for file in batch_files:\n",
    "                data = np.load(os.path.join(folder, file))\n",
    "                color_images = data['colorImages']  # (231, 237, 3, num_images)\n",
    "                \n",
    "                for j in range(color_images.shape[3]):\n",
    "                    img = color_images[:, :, :, j]\n",
    "                    img_resized = cv2.resize(img, img_size)\n",
    "                    img_resized = img_resized / 255.0  # Normalize to [0, 1]\n",
    "                    batch_images.append(img_resized)\n",
    "                    \n",
    "                    # Apply Gaussian blur to simulate low-quality CCTV footage\n",
    "                    blurry_img = cv2.GaussianBlur(img_resized, (5, 5), 0)\n",
    "                    batch_blurry_images.append(blurry_img)\n",
    "            \n",
    "            yield (np.array(batch_blurry_images), np.array(batch_images))  # (blurry, high-res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Advanced Autoencoder Model for Image Reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_advanced_autoencoder(input_shape=(128, 128, 3)):\n",
    "    encoder_input = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Conv2DTranspose(256, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = models.Model(encoder_input, decoded)\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compile the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the autoencoder\n",
    "autoencoder = build_advanced_autoencoder(input_shape=(128, 128, 3))\n",
    "autoencoder.compile(optimizer='adam', loss='mse')  # Mean Squared Error for image reconstruction\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create a Training Pipeline using Data Generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset folder path\n",
    "dataset_folder = 'dataset/'\n",
    "\n",
    "# Create the train generator\n",
    "train_generator = npz_image_generator(dataset_folder, batch_size=32, img_size=(128, 128))\n",
    "\n",
    "# Define the training dataset from the generator\n",
    "def create_dataset(generator, batch_size=32):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32)\n",
    "        )\n",
    "    ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = create_dataset(lambda: npz_image_generator(dataset_folder, batch_size=32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train the Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = autoencoder.fit(train_dataset, epochs=50, steps_per_epoch=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Reconstruction Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the original (blurry) and reconstructed images\n",
    "def display_reconstructed_images(model, dataset, num_images=5):\n",
    "    for blurry_images, high_res_images in dataset.take(1):  # Take a single batch\n",
    "        reconstructed_images = model.predict(blurry_images)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i in range(num_images):\n",
    "            # Display original blurry image\n",
    "            ax = plt.subplot(3, num_images, i + 1)\n",
    "            plt.imshow(blurry_images[i])\n",
    "            plt.title(\"Blurry Image\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            # Display reconstructed image\n",
    "            ax = plt.subplot(3, num_images, i + 1 + num_images)\n",
    "            plt.imshow(reconstructed_images[i])\n",
    "            plt.title(\"Reconstructed Image\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            # Display high-res image (ground truth)\n",
    "            ax = plt.subplot(3, num_images, i + 1 + 2 * num_images)\n",
    "            plt.imshow(high_res_images[i])\n",
    "            plt.title(\"Original High-Res Image\")\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# Visualize some reconstructions\n",
    "display_reconstructed_images(autoencoder, train_dataset, num_images=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: (Optional) Save the Model for Future Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "autoencoder.save('face_reconstruction_autoencoder.h5')\n",
    "\n",
    "# Load the model (later for inference)\n",
    "# from tensorflow.keras.models import load_model\n",
    "# autoencoder = load_model('face_reconstruction_autoencoder.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: (Optional) Convert .npz Files to TFRecords for Future Efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def convert_to_tfrecord(npz_folder, output_file):\n",
    "    with tf.io.TFRecordWriter(output_file) as writer:\n",
    "        for file in os.listdir(npz_folder):\n",
    "            if file.endswith('.npz'):\n",
    "                data = np.load(os.path.join(npz_folder, file))\n",
    "                color_images = data['colorImages']\n",
    "                \n",
    "                for j in range(color_images.shape[3]):\n",
    "                    img = color_images[:, :, :, j]\n",
    "                    img_bytes = tf.io.encode_jpeg(img.astype(np.uint8)).numpy()\n",
    "                    \n",
    "                    feature = {\n",
    "                        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_bytes]))\n",
    "                    }\n",
    "                    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                    writer.write(example.SerializeToString())\n",
    "\n",
    "# Convert dataset to TFRecords\n",
    "convert_to_tfrecord('dataset/', 'face_reconstruction.tfrecord')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Approach:\n",
    "- **Efficient Loading**: We use a data generator to avoid loading the entire dataset into memory at once.\n",
    "\n",
    "- **Model Architecture**: An advanced autoencoder architecture is used for reconstructing faces.\n",
    "\n",
    "- **Training Pipeline**: tf.data API is used to efficiently manage large datasets and ensure fast data loading.\n",
    "\n",
    "- **Visualization**: We visualize the results to compare the blurry input images with the reconstructed high-resolution ones.\n",
    "\n",
    "- **Optimization**: Optionally, converting .npz files to TFRecords speeds up file I/O operations in future training sessions.\n",
    "\n",
    "*optimized for both memory and speed when dealing with large datasets for CCTV footage enhancement and reconstruction.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
