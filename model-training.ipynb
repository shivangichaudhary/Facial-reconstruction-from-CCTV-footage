{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and define dataset path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "dataset_path = 'dataset/'  # Adjusted to point to the new folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Loading with Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "def npz_image_generator(folder, batch_size=32, img_size=(128, 128)):\n",
    "    files = [f for f in os.listdir(folder) if f.endswith('.npz')]\n",
    "    num_files = len(files)\n",
    "    \n",
    "    while True:\n",
    "        for i in range(0, num_files, batch_size):\n",
    "            batch_files = files[i:i + batch_size]\n",
    "            batch_images = []\n",
    "            batch_blurry_images = []\n",
    "            \n",
    "            for file in batch_files:\n",
    "                data = np.load(os.path.join(folder, file))\n",
    "                color_images = data['colorImages']  # Shape (height, width, channels, num_images)\n",
    "                \n",
    "                for j in range(color_images.shape[3]):\n",
    "                    # Extract image and preprocess\n",
    "                    img = color_images[:, :, :, j]\n",
    "                    img_resized = cv2.resize(img, img_size)\n",
    "                    img_resized = img_resized / 255.0  # Normalize\n",
    "                    batch_images.append(img_resized)\n",
    "                    \n",
    "                    # Create blurry image\n",
    "                    blurry_img = cv2.GaussianBlur(img_resized, (5, 5), 0)\n",
    "                    batch_blurry_images.append(blurry_img)\n",
    "                    \n",
    "            yield (np.array(batch_blurry_images), np.array(batch_images))  # Return blurry and high-quality images\n",
    "\n",
    "# Path to dataset\n",
    "dataset_path = 'dataset/'  # Adjust to point to your dataset folder\n",
    "\n",
    "# Example usage of the generator\n",
    "train_generator = npz_image_generator(dataset_path, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Using tf.keras Image Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(generator, batch_size=32):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32)\n",
    "        )\n",
    "    ).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Create dataset object\n",
    "train_dataset = create_dataset(lambda: npz_image_generator(dataset_path, batch_size=32))\n",
    "\n",
    "# Build your advanced autoencoder model (same as before)\n",
    "advanced_autoencoder = build_advanced_autoencoder((128, 128, 3))\n",
    "\n",
    "# Compile the model\n",
    "advanced_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model with the generator\n",
    "history = advanced_autoencoder.fit(train_dataset, epochs=50, steps_per_epoch=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preprocessed Data for Reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_preprocessed_data_as_h5(folder, output_file, img_size=(128, 128)):\n",
    "    with h5py.File(output_file, 'w') as h5file:\n",
    "        for file in os.listdir(folder):\n",
    "            if file.endswith('.npz'):\n",
    "                data = np.load(os.path.join(folder, file))\n",
    "                color_images = data['colorImages']\n",
    "                for i in range(color_images.shape[3]):\n",
    "                    img = color_images[:, :, :, i]\n",
    "                    img_resized = cv2.resize(img, img_size)\n",
    "                    img_resized = img_resized / 255.0  # Normalize\n",
    "\n",
    "                    # Save to HDF5\n",
    "                    dataset_name = f\"{file}_{i}\"\n",
    "                    h5file.create_dataset(dataset_name, data=img_resized)\n",
    "\n",
    "# Save preprocessed data\n",
    "save_preprocessed_data_as_h5(dataset_path, 'preprocessed_data.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data from HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_image_generator(h5_file, batch_size=32):\n",
    "    with h5py.File(h5_file, 'r') as h5file:\n",
    "        dataset_names = list(h5file.keys())\n",
    "        num_samples = len(dataset_names)\n",
    "        \n",
    "        while True:\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                batch_datasets = dataset_names[i:i + batch_size]\n",
    "                batch_images = []\n",
    "                batch_blurry_images = []\n",
    "                \n",
    "                for dataset_name in batch_datasets:\n",
    "                    img_resized = h5file[dataset_name][:]\n",
    "                    batch_images.append(img_resized)\n",
    "                    \n",
    "                    # Create blurry image\n",
    "                    blurry_img = cv2.GaussianBlur(img_resized, (5, 5), 0)\n",
    "                    batch_blurry_images.append(blurry_img)\n",
    "                \n",
    "                yield (np.array(batch_blurry_images), np.array(batch_images))\n",
    "\n",
    "# Example usage\n",
    "h5_train_generator = h5_image_generator('preprocessed_data.h5', batch_size=32)\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: h5_train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32)\n",
    "    )\n",
    ").batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset function and load the images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from all npz files in the dataset\n",
    "def load_dataset(folder):\n",
    "    images = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.npz'):\n",
    "            data = np.load(os.path.join(folder, file))\n",
    "            color_images = data['colorImages']  # Shape (height, width, channels, num_images)\n",
    "            for i in range(color_images.shape[3]):\n",
    "                images.append(color_images[:, :, :, i])  # Extract and append each image\n",
    "    return np.array(images)\n",
    "\n",
    "# Load all images\n",
    "images = load_dataset(dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images: resize and normalize\n",
    "def preprocess_images(images, img_size=(128, 128)):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img_resized = cv2.resize(img, img_size)\n",
    "        img_resized = img_resized / 255.0  # Normalize to range [0, 1]\n",
    "        resized_images.append(img_resized)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "# Apply preprocessing\n",
    "images = preprocess_images(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create blurry images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blurry images by applying Gaussian blur (this simulates low-quality input)\n",
    "def blur_images(images):\n",
    "    blurred_images = []\n",
    "    for img in images:\n",
    "        blurred_img = cv2.GaussianBlur(img, (5, 5), 0)  # Apply Gaussian blur\n",
    "        blurred_images.append(blurred_img)\n",
    "    return np.array(blurred_images)\n",
    "\n",
    "# Create the blurry versions\n",
    "blurred_images = blur_images(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(blurred_images, images, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the advanced model architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Advanced Model Architecture ###\n",
    "# Residual Block for better learning of features\n",
    "def residual_block(x, filters):\n",
    "    skip = x\n",
    "    x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = layers.add([x, skip])\n",
    "    return x\n",
    "\n",
    "# U-Net Architecture with residual connections\n",
    "def build_advanced_autoencoder(input_shape):\n",
    "    # Encoder\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Down-sampling with residual blocks\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Decoder with skip connections (U-Net style)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    # Output layer\n",
    "    x = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    return models.Model(input_img, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the advanced autoencoder model\n",
    "advanced_autoencoder = build_advanced_autoencoder((128, 128, 3))\n",
    "\n",
    "# Compile the model with MSE Loss and Adam optimizer\n",
    "advanced_autoencoder.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = advanced_autoencoder.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "# Save the trained model\n",
    "advanced_autoencoder.save('advanced_face_reconstruction_autoencoder.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training process\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on validation samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on some validation samples\n",
    "def test_advanced_autoencoder(model, blurred_images, original_images, num_samples=5):\n",
    "    reconstructed_images = model.predict(blurred_images[:num_samples])\n",
    "    for i in range(num_samples):\n",
    "        # Plot original, blurry, and reconstructed images side by side\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(original_images[i])\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(blurred_images[i])\n",
    "        plt.title('Blurry')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(reconstructed_images[i])\n",
    "        plt.title('Reconstructed')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Test the model on the validation set\n",
    "test_advanced_autoencoder(advanced_autoencoder, x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "\n",
    "dataset_path = 'dataset/'  # Adjusted to point to the new folder\n",
    "\n",
    "# Load data from npz files in the dataset with resizing and normalization\n",
    "def load_and_preprocess_single_file(file, img_size=(128, 128)):\n",
    "    data = np.load(file)\n",
    "    color_images = data['colorImages']\n",
    "    resized_images = [cv2.resize(img, img_size) / 255.0 for img in color_images]\n",
    "    return np.array(resized_images)\n",
    "\n",
    "def preprocess_file(file):\n",
    "    return load_and_preprocess_single_file(file)\n",
    "\n",
    "# Load all images in parallel\n",
    "def load_all_images_parallel(folder, img_size=(128, 128)):\n",
    "    files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.npz')]\n",
    "    with Pool() as pool:\n",
    "        images = pool.map(preprocess_file, files)  # Use the defined function here\n",
    "    return np.concatenate(images, axis=0)  # Concatenate along the first axis\n",
    "\n",
    "# Load all images\n",
    "images = load_all_images_parallel(dataset_path)\n",
    "\n",
    "# Create blurry images by applying Gaussian blur\n",
    "def blur_images(images):\n",
    "    return np.array([cv2.GaussianBlur(img, (5, 5), 0) for img in images])\n",
    "\n",
    "# Create the blurry versions\n",
    "blurred_images = blur_images(images)\n",
    "\n",
    "# Split into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(blurred_images, images, test_size=0.1, random_state=42)\n",
    "\n",
    "### Advanced Model Architecture ###\n",
    "# Residual Block for better learning of features\n",
    "def residual_block(x, filters):\n",
    "    skip = x\n",
    "    x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = layers.add([x, skip])\n",
    "    return x\n",
    "\n",
    "# U-Net Architecture with residual connections\n",
    "def build_advanced_autoencoder(input_shape):\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Down-sampling with residual blocks\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Decoder with skip connections (U-Net style)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    # Output layer\n",
    "    x = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    return models.Model(input_img, x)\n",
    "\n",
    "# Build the advanced autoencoder model\n",
    "advanced_autoencoder = build_advanced_autoencoder((128, 128, 3))\n",
    "\n",
    "# Compile the model with MSE Loss and Adam optimizer\n",
    "advanced_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = advanced_autoencoder.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "# Save the trained model\n",
    "advanced_autoencoder.save('advanced_face_reconstruction_autoencoder.h5')\n",
    "\n",
    "# Visualize the training process\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Test the model on some validation samples\n",
    "def test_advanced_autoencoder(model, blurred_images, original_images, num_samples=5):\n",
    "    reconstructed_images = model.predict(blurred_images[:num_samples])\n",
    "    for i in range(num_samples):\n",
    "        # Plot original, blurry, and reconstructed images side by side\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(original_images[i])\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(blurred_images[i])\n",
    "        plt.title('Blurry')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(reconstructed_images[i])\n",
    "        plt.title('Reconstructed')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Test the model on the validation set\n",
    "test_advanced_autoencoder(advanced_autoencoder, x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
