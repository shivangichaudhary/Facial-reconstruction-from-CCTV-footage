{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2680055,"sourceType":"datasetVersion","datasetId":2946}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nimport cv2\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm  # For progress bars\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:55:34.678190Z","iopub.execute_input":"2024-09-26T03:55:34.678584Z","iopub.status.idle":"2024-09-26T03:55:34.684449Z","shell.execute_reply.started":"2024-09-26T03:55:34.678549Z","shell.execute_reply":"2024-09-26T03:55:34.683503Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# --- Load Dataset ---\n","metadata":{}},{"cell_type":"code","source":"# Define your dataset paths (adjust the paths as needed)\ndataset_dirs = [\n    '/kaggle/input/youtube-faces-with-facial-keypoints/youtube_faces_with_keypoints_full_1/youtube_faces_with_keypoints_full_1',\n    '/kaggle/input/youtube-faces-with-facial-keypoints/youtube_faces_with_keypoints_full_2/youtube_faces_with_keypoints_full_2',\n    '/kaggle/input/youtube-faces-with-facial-keypoints/youtube_faces_with_keypoints_full_3/youtube_faces_with_keypoints_full_3',\n    '/kaggle/input/youtube-faces-with-facial-keypoints/youtube_faces_with_keypoints_full_4/youtube_faces_with_keypoints_full_4'\n]\n\n# Collecting all files from the specified directories\nfiles = []\nfor dataset_dir in dataset_dirs:\n    files += [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith('.npz')]\n\n# Debugging step: print the number of files found\nprint(f\"Number of files found: {len(files)}\")\nif len(files) == 0:\n    print(\"No files found! Please check the directory paths and file structure.\")\nelse:\n    # Perform train-test split if files are found\n    train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n\n    print(f\"Training set size: {len(train_files)} files\")\n    print(f\"Validation set size: {len(val_files)} files\")","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:55:36.432246Z","iopub.execute_input":"2024-09-26T03:55:36.432624Z","iopub.status.idle":"2024-09-26T03:55:36.472319Z","shell.execute_reply.started":"2024-09-26T03:55:36.432587Z","shell.execute_reply":"2024-09-26T03:55:36.471483Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Number of files found: 2194\nTraining set size: 1755 files\nValidation set size: 439 files\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# --- Data Generator Class ---\n","metadata":{}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self, files, batch_size=32, sample_ratio=0.1, img_size=(256, 256), shuffle=True, return_names=False):\n        self.files = files\n        self.batch_size = batch_size\n        self.sample_ratio = sample_ratio\n        self.img_size = img_size\n        self.shuffle = shuffle\n        self.return_names = return_names\n        \n        if self.shuffle:\n            random.shuffle(self.files)\n\n    def __len__(self):\n        return int(np.floor(len(self.files) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_files = self.files[index * self.batch_size:(index + 1) * self.batch_size]\n\n        images, bboxes, landmarks_2d, landmarks_3d, image_names = [], [], [], [], []\n        for npz_file in batch_files:\n            data = np.load(npz_file)\n            color_images = data['colorImages']\n            bboxes_data = data['boundingBox']\n            landmarks2D_data = data['landmarks2D']\n            landmarks3D_data = data['landmarks3D']\n\n            num_frames = color_images.shape[-1]\n            sampled_indices = random.sample(range(num_frames), int(self.sample_ratio * num_frames))\n\n            filename = os.path.basename(npz_file).split('.')[0]\n\n            for idx in sampled_indices:\n                img = color_images[..., idx]\n                img = cv2.resize(img, self.img_size)\n                img = img / 255.0  # Normalize\n\n                images.append(img)  # Use original images\n\n                bboxes.append(bboxes_data[..., idx])\n                landmarks_2d.append(landmarks2D_data[..., idx])\n                landmarks_3d.append(landmarks3D_data[..., idx])\n                image_names.append(filename)\n\n        images = np.array(images)\n\n        if self.return_names:\n            return images, images, image_names  # Return image names for visualization\n        else:\n            return images, images  # Don't return names during training\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.files)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:55:38.608123Z","iopub.execute_input":"2024-09-26T03:55:38.608533Z","iopub.status.idle":"2024-09-26T03:55:38.621608Z","shell.execute_reply.started":"2024-09-26T03:55:38.608494Z","shell.execute_reply":"2024-09-26T03:55:38.620489Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# --- Train-Validation Split ---\ntrain_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n\n# --- Data Generators ---\ntrain_generator = DataGenerator(files=train_files, batch_size=8, sample_ratio=0.05, img_size=(256, 256), shuffle=True)\nval_generator = DataGenerator(files=val_files, batch_size=8, sample_ratio=0.05, img_size=(256, 256), shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:55:39.832169Z","iopub.execute_input":"2024-09-26T03:55:39.832506Z","iopub.status.idle":"2024-09-26T03:55:39.841119Z","shell.execute_reply.started":"2024-09-26T03:55:39.832474Z","shell.execute_reply":"2024-09-26T03:55:39.840207Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# --- Autoencoder Model ---\n","metadata":{}},{"cell_type":"code","source":"def build_autoencoder():\n    input_img = keras.Input(shape=(256, 256, 3))  # Keep this as it is, can reduce later if necessary\n\n    # Encoder\n    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n    x = layers.Dropout(0.2)(x)\n\n    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n    x = layers.Dropout(0.2)(x)\n\n    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n\n    # Decoder\n    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n    x = layers.UpSampling2D((2, 2))(x)\n    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = layers.UpSampling2D((2, 2))(x)\n    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = layers.UpSampling2D((2, 2))(x)\n    decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\n    # Autoencoder model\n    autoencoder = keras.Model(input_img, decoded)\n    autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n    autoencoder.summary()\n\n    return autoencoder","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:55:41.957276Z","iopub.execute_input":"2024-09-26T03:55:41.957954Z","iopub.status.idle":"2024-09-26T03:55:41.969196Z","shell.execute_reply.started":"2024-09-26T03:55:41.957914Z","shell.execute_reply":"2024-09-26T03:55:41.968159Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# --- Multi-GPU Strategy ---\n","metadata":{}},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n    autoencoder = build_autoencoder()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:55:44.152340Z","iopub.execute_input":"2024-09-26T03:55:44.153318Z","iopub.status.idle":"2024-09-26T03:55:45.464597Z","shell.execute_reply.started":"2024-09-26T03:55:44.153274Z","shell.execute_reply":"2024-09-26T03:55:45.463650Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m3,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m73,792\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ up_sampling2d_2 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │         \u001b[38;5;34m3,459\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ up_sampling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,459</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,795\u001b[0m (788.26 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,795</span> (788.26 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,347\u001b[0m (786.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,347</span> (786.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# --- Model Training with Callbacks ---\n","metadata":{}},{"cell_type":"code","source":"# --- Callbacks ---\ncallbacks = [\n    ModelCheckpoint('/kaggle/working/best_model.keras', save_best_only=True, monitor='val_loss', mode='min'),\n    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n]\n\n# --- Training Loop ---\nautoencoder.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=50,\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:55:51.212908Z","iopub.execute_input":"2024-09-26T03:55:51.213290Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2024-09-26 03:56:01.249385: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_186/cond/StatefulPartitionedCall/functional_1_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 2s/step - loss: 0.0258 - val_loss: 0.0685 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 1s/step - loss: 0.0119 - val_loss: 0.0391 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 1s/step - loss: 0.0093 - val_loss: 0.0143 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - loss: 0.0078 - val_loss: 0.0067 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 1s/step - loss: 0.0070 - val_loss: 0.0085 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 1s/step - loss: 0.0058 - val_loss: 0.0076 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - loss: 0.0054 - val_loss: 0.0068 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - loss: 0.0051 - val_loss: 0.0067 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 1s/step - loss: 0.0048 - val_loss: 0.0073 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 1s/step - loss: 0.0045 - val_loss: 0.0063 - learning_rate: 2.0000e-05\nEpoch 11/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 1s/step - loss: 0.0044 - val_loss: 0.0060 - learning_rate: 2.0000e-05\nEpoch 12/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 1s/step - loss: 0.0044 - val_loss: 0.0063 - learning_rate: 2.0000e-05\nEpoch 13/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 1s/step - loss: 0.0042 - val_loss: 0.0061 - learning_rate: 2.0000e-05\nEpoch 14/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 1s/step - loss: 0.0041 - val_loss: 0.0065 - learning_rate: 2.0000e-05\nEpoch 15/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - loss: 0.0042 - val_loss: 0.0067 - learning_rate: 2.0000e-05\nEpoch 16/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 1s/step - loss: 0.0041 - val_loss: 0.0061 - learning_rate: 2.0000e-05\nEpoch 17/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 1s/step - loss: 0.0040 - val_loss: 0.0062 - learning_rate: 4.0000e-06\nEpoch 18/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 1s/step - loss: 0.0040 - val_loss: 0.0064 - learning_rate: 4.0000e-06\nEpoch 19/50\n\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - loss: 0.0040 - val_loss: 0.0064 - learning_rate: 4.0000e-06\nEpoch 20/50\n\u001b[1m176/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 0.0040","output_type":"stream"}]},{"cell_type":"markdown","source":"# --- Save the model after training ---\n","metadata":{}},{"cell_type":"code","source":"autoencoder.save(\"/kaggle/working/final_model.keras\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# --- Testing and Visualization ---\n","metadata":{}},{"cell_type":"code","source":"test_generator = DataGenerator(files=val_files, batch_size=16, sample_ratio=0.05, img_size=(256, 256), shuffle=False, return_names=True)\ntest_images, _, test_names = test_generator[0]\n\nreconstructed_images = autoencoder.predict(test_images[:5])\n\n# --- Display Function ---\n\ndef display_comparison(original, reconstructed, names, n=5):\n    plt.figure(figsize=(15, 5))\n    for i in range(n):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(original[i])\n        plt.title(f\"Original: {names[i]}\")\n        plt.axis(\"off\")\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(reconstructed[i])\n        plt.title(\"Reconstructed\")\n        plt.axis(\"off\")\n    plt.show()\n\n# --- Display Comparison ---\ndisplay_comparison(test_images[:5], reconstructed_images, test_names[:5], n=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# --- Save Comparisons ---\n","metadata":{}},{"cell_type":"code","source":"def save_comparisons(original, enhanced, names, folder=\"/kaggle/working/prediction\"):\n    os.makedirs(folder, exist_ok=True)\n    for i in range(len(original)):\n        original_img = (original[i] * 255).astype(np.uint8)\n        enhanced_img = (enhanced[i] * 255).astype(np.uint8)\n        combined = np.hstack((original_img, enhanced_img))\n        cv2.imwrite(os.path.join(folder, f\"{names[i]}_comparison.png\"), combined)\n\nsave_comparisons(test_images[:5], reconstructed_images, test_names[:5])\n","metadata":{},"execution_count":null,"outputs":[]}]}